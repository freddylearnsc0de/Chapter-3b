{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data Files with pandas\n",
    "\n",
    "There are three data files. Each file contains the reaction times (RTs) from 10 trials of a relatively simple task in which participants had to indicate which direction a briefly-presented arrow was pointing. The RTs are in seconds (s). Each file contains the RTs from a different participant. In each file there are three columns. You can determine what the columns are by looking at the first row (header) of each file.\n",
    "\n",
    "In this exercise, we will read in the data from the three files in the `data` directory: `s1.csv`, `s2.csv`, and `s3.csv`, and combine them into a single DataFrame. We will save that DataFrame, and then then calculate the mean RT for each participant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "To start the process, I typed the first two lines of the prompt below:\n",
    "\n",
    "```python\n",
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "```\n",
    "\n",
    "After I hit `Enter`, Copilot suggested the third line of the prompt, which I accepted by hitting `Tab`:\n",
    "\n",
    "```python\n",
    "# write the result to a csv file\n",
    "```\n",
    "\n",
    "The cells below all reflect prompts written on the basis of the instructions above, and code generated entirely by Copilot. While your experience may be different, in writing this lesson we only had to type the first 2-line prompt, and Copilot generated not only the code but the other prompts/comments. \n",
    "\n",
    "However, you have to get used to the flow of working with Copilot. Copilot encourages a good coding style, and so it will sometimes only generate code if you hit `Enter` twice, so that there's an empty line between your prompt and the code. The same is true *after* a line of code: Copilot may force you to hit `Enter` twice before it generates the next prompt or line of code.\n",
    "\n",
    "After I typed the first two lines of the prompt below, and accepted the third line of the prompt (which was suggested by Copilot), I had to hit `Enter` twice to get the first line of code (`import pandas as pd`) generated.\n",
    "\n",
    "Although we intended to only read and combine the data files, after I typed the first two lines of the prompt and hit `Enter`, Copilot added a third suggested line to the prompt after I hit `Enter` the first time, which was to `write the dataframe to a csv file`. This is pretty cool, since that was also part of the instructions above! Is Copilot a mind-reader? No, it's just a very good predictor of what you might want to do next, based on the prompt you've written. It's a pretty common task in data science to read in a set of individual data files, concatenate them into a single DataFrame, and then save that DataFrame to a file for later use. So, Copilot is just doing what it's trained to do, which is to predict what you might want to do next, based on the prompt you've written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "# write the result to a csv file\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# get data file names\n",
    "path =r'./data'\n",
    "filenames = glob.glob(path + \"/s*.csv\")\n",
    "\n",
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "dfs = []\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "    # read in the file\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "\n",
    "    # append the file to the list of dataframes\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate them into one dataframe\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# write the result to a csv file\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "# use list comprehension to do this\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# get data file names\n",
    "path =r'./data'\n",
    "filenames = glob.glob(path + \"/s*.csv\")\n",
    "\n",
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "dfs = [pd.read_csv(filename, index_col=None, header=0) for filename in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code ran without errors, but we didn't ask for any output. Next we'll to some checks to confirm that the code ran correctly, as described in the instructions. We'll start by checking the number of columns in the DataFrame. As noted above, there should be three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# check number of collums in dataframe\n",
    "print(df.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the DataFrame has 3 columns, as expected. Next, we'll check that we get the expected number of rows (30) and columns (3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n"
     ]
    }
   ],
   "source": [
    "# show the number of rows and columns in the df\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also were instructed to raise an error message if the number of rows or columns is incorrect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise an error message if number of rows in df is not 30, or the number of columns is not 3\n",
    "if df.shape != (30, 3):\n",
    "    raise ValueError('The number of rows in df is not 30, or the number of columns is not 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Test\n",
    "This generates no output. This is a Good Thing, because it means that the number of rows and columns is correct. However, it's a bit dangerous to assume no news is good news, because no news could also mean your code is not working. So, we should test that the error message is generated if we change the expected number of rows or columns.\n",
    "\n",
    "We don't want to actually remove any rows from the DataFrame, but we can use **slicing** to create a view of the DataFrame that has fewer rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of rows in df is not 10, or the number of columns is not 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df_slice \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m10\u001b[39m, :]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_slice\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of rows in df is not 10, or the number of columns is not 3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of rows in df is not 10, or the number of columns is not 3"
     ]
    }
   ],
   "source": [
    "# create a slice of df with the first 10 rows and all columns\n",
    "# raise an error message if number of rows in df is not 30, or the number of columns is not 3\n",
    "\n",
    "df_slice = df.iloc[:10, :]\n",
    "\n",
    "if df_slice.shape != (30, 3):\n",
    "    raise ValueError('The number of rows in df is not 10, or the number of columns is not 3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an `AssertionError`, which is a Good Thing because it confirms that our error-checking code is working. We can do the same thing to test the error-checking code for the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of rows in df is not 30, or the number of columns is not 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df_slice \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_slice\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of rows in df is not 30, or the number of columns is not 3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of rows in df is not 30, or the number of columns is not 3"
     ]
    }
   ],
   "source": [
    "# create a slice of df with the first all rows and 2 columns\n",
    "# raise an error message if number of rows in df is not 30, or the number of columns is not 3\n",
    "\n",
    "df_slice = df.iloc[:, :2]\n",
    "\n",
    "if df_slice.shape != (30, 3):\n",
    "    raise ValueError('The number of rows in df is not 30, or the number of columns is not 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, our code will throw errors if the number of rows or columns is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Mean RT for Each Participant... and Our First Bug\n",
    "Our next instruction is to calculate the mean RT for each participant. Let's prompt Copilot to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    0.389548\n",
       "s2    0.444785\n",
       "s3    0.446009\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT for each participantID\n",
    "\n",
    "df.groupby('participantID')['RT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.341722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.494156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.468912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>s1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.368142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participantID  trial        RT\n",
       "28            s1      9  0.341722\n",
       "15            s3      6  0.494156\n",
       "0             s2      1  0.433094\n",
       "9             s2     10  0.468912\n",
       "25            s1      6  0.368142"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Debugging Copilot-Generated Code\n",
    "\n",
    "Typically, when you get a long, scary error message like the one above, you can ignore a lof of what is in the middle. The most important parts are the last line, which tells you what the error is, and the first lines, which usually indicate what line in the code you tried to run caused the error. What's in between is the *stack trace*, which is a list of all the functions that were called in the process of trying to run the code. But most of the time, the error is a result of the code you wrote (the first lines), not the code in the underlying Python functions that your code called (the middle lines).\n",
    "\n",
    "In this case, we see a `KeyError: 'participant'` at the bottom of the error message. Recall that Python dictionaries are sets of **key**-value pairs. The keys are the names of the columns, and the values are the data in those columns. \n",
    "\n",
    "You can think of a pandas DataFrame as a dictionary in which the column names are keys, and the values in that column are its values. This is a common way that pandas functions refer to column names and their values. So the error message above indicates that the code tried to access a column called `subject` in the DataFrame, but that column doesn't exist. We can see at the top of the error message that the code that caused the error is: `---> 2 df.groupby('participant').mean()`. This means it's line 2 of the cell above that caused the error. \n",
    "\n",
    "As a novice coder, however, you might not know or remember that pandas DataFrames represent column names and data as dictionary key-value pairs. If you don't understand what an error means, you can use Copilot to help you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Copilot to Explain Errors and Suggest Fixes\n",
    "\n",
    "Somewhat counterintuitively, even though Copilot can generate code with bugs, it can also provide feedback on errors in the code it generated. \n",
    "\n",
    "Copilot has a few features that can help you diagnose and fix your code. The one we have found most effective is Copilot Chat. For this reason, we won't describe other methods, such as Copilot's \"Fix\" feature, which is described in the [Copilot documentation](https://copilot.github.com/#/guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](images/chat_icon.png)  Copilot Chat\n",
    "\n",
    " Another, really useful option is the `Chat` option, which you can option by clicking the `Chat` icon (shown above) in the Activity Bar (left side of VS Code). This allows you to have a conversation with Copilot about what you want to do. If you've used [Chat-GPT](https://chat.openai.com/) before, this will be familiar to you as it's essentially the same type of natural-language interface.\n",
    "\n",
    "There are different approaches to using Copilot Chat to help fix an error. One is to click in the cell that generates the error, and then click in the Copilot Chat input box, and typing: \n",
    "\n",
    "```\n",
    "the selected cell generates an error. how can i fix this error?\n",
    "``` \n",
    "\n",
    "In response to this prompt for the present error, I got the following response:\n",
    "\n",
    ">If you are getting an error with the selected cell, there could be a few reasons why. Here are some possible solutions:\n",
    ">\n",
    ">1. Check that the 'participant' column is present in the dataframe. You can do this by printing out the dataframe using the `print()` function and checking that the 'participant' column is present.\n",
    ">\n",
    ">2. Check that the 'participant' column is spelled correctly. If the column is misspelled, you will get a \"KeyError\" when trying to group by that column.\n",
    ">\n",
    ">3. Check that the 'participant' column is of the correct data type. If the 'participant' column is not a string or categorical data type, you may need to convert it using the `astype()` method.\n",
    ">\n",
    ">4. Check that the dataframe contains numerical columns. If the dataframe only contains non-numerical columns, you will get a \"DataError\" when trying to calculate the mean.\n",
    ">\n",
    ">5. Check that the dataframe does not contain missing values. If the dataframe contains missing values, you may need to remove them using the `dropna()` method before calculating the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Error with Copilot's Help\n",
    "\n",
    "These are actually really good responses, and they are provided in a logical order to go through in debugging. We could work through them in order, but — spoiler alert — the first suggestion actually leads to a solution. \n",
    "\n",
    "### Check that the 'participant' Column is Present in the DataFrame\n",
    "The first thing to do is to check that the column exists, and is spelled correctly. So let's start with that. Do you remember how to check the names of the columns in a pandas DataFrame? If not, you can write a Copilot prompt to help you out. In the cell below, write a prompt that will print the names of the columns in the DataFrame. Then run the cell, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participantID', 'trial', 'RT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the names of the columns in df\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to look at the first few rows of the DataFrame, which includes the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  participantID  trial        RT\n",
      "0            s2      1  0.433094\n",
      "1            s2      2  0.392526\n",
      "2            s2      3  0.396831\n",
      "3            s2      4  0.417988\n",
      "4            s2      5  0.371810\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third option, when using Jupyter notebooks with VS Code, is to click on the `Variables` button in the toolbar at the top of the notebook window. This will pop up a variable viewer in sub-window below your notebook. You can click on the variable names to see their values. For DataFrames, it actually shows a list of the columns in the window, and you can double-click on the variable name to see the contents of the DataFrame in another window, the **Data Viewer**. This view is similar to a spreadsheet. In fact, you can directly edit values in the Data Viewer. *You should never directly edit values like this*, however. Any steps you do manually are not documented in your code, and are not reproducible.  \n",
    "\n",
    "The screenshot below shows the variables and Data Viewer for the current context.\n",
    "\n",
    "![](images/inspectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Solution\n",
    "\n",
    "Using any of the three approaches above, when we look at the column names, we see that they are `participantID`, `trial`, and `RT`. The code that generated the error was trying to access a column called `participant`, which doesn't exist. It should be `participantID`. So we need to change the code to access the correct column name. Or, engineer our prompt to do so.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "This is an important lesson on prompt engineering. You're more likely to get working code if you use the actual variable names in the prompt, rather than expecting Copilot to make inferences about what variable you're referring to based on the context.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               trial        RT\n",
      "participantID                 \n",
      "s1               5.5  0.389548\n",
      "s2               5.5  0.444785\n",
      "s3               5.5  0.446009\n"
     ]
    }
   ],
   "source": [
    "# calculate mean RT for each participantID\n",
    "print(df.groupby('participantID').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, however the code is providing means for both columns in the DataFrame (`trial` and `RT`), not just for `RT` (sometimes the same prompt actually does select only `RT` but we'll explore when it doesn't). We can add to our prompt to tell it not to include `trial` in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RT\n",
       "participantID          \n",
       "s1             0.389548\n",
       "s2             0.444785\n",
       "s3             0.446009"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('participantID').mean().drop(columns='trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above generated code does what we want. However, from the perspectives of coding style and efficiency, it's not optimal. Python executes this **chained command** from left to right. So, it first computes the mean for each column in the DataFrame, and then drops the column `trial`.\n",
    "\n",
    "It seems unnecessary to compute the mean for `trial` and then drop it. This isn't really Copilot's fault — we did explicitly tell it not to show the mean for trial, but it's not smart enough to know that we don't want to compute it in the first place; it seems to have interpreted our prompt as a literal sequence of commands.\n",
    "\n",
    "We can modify the prompt in a way that generates more efficient code, by being specific about the column that we do want, rather than what we don't want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participantID\n",
      "s1    0.389548\n",
      "s2    0.444785\n",
      "s3    0.446009\n",
      "Name: RT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('participantID')['RT'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By way of showing how sensitive Copilot is to the structure of your prompt, a slightly different (and arguably more logical) phrasing of the prompt above generates the less-efficient code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     RT\n",
      "participantID          \n",
      "s1             0.389548\n",
      "s2             0.444785\n",
      "s3             0.446009\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('participantID').mean().drop('trial', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "One thing you may notice is that the result of the last command above is nicely-formatted when it is displayed, whereas the one before it is in a more \"raw\" format. This is not really important here, but it's worth understanding why the difference occurs. When you call a pandas DataFrame it prints in a nicely formatted output. However, when you call a pandas Series (which is a single column), it prints in a more detailed but less \"pretty\" way. \n",
    "\n",
    "In the output immediately above, the code created a DataFrame with two columns (`trial` and `RT`) and then dropped the `trial` column, but as such it remained a DataFrame and so was nicely formatted.\n",
    "\n",
    "In contrast, the output of using the `mean()` method on a single column (`RT`) in the cell above that is a Series.  \n",
    "<p><p>\n",
    "We'll worry about the formatting later, but it's good to understand why it happens because the distinction between DataFrames and Series often causes confusion and errors if it's not understood.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
